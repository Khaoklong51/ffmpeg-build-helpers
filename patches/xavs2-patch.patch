diff --git a/build/linux/configure b/build/linux/configure
index 1760c31..7941abe 100755
--- a/build/linux/configure
+++ b/build/linux/configure
@@ -954,7 +954,7 @@ ASFLAGS="$ASFLAGS -DSTACK_ALIGNMENT=$stack_alignment"
 CPU_ENDIAN="little-endian"
 if [ $compiler = GNU ]; then
     echo "int i[2] = {0x42494745,0}; double f[2] = {0x1.0656e6469616ep+102,0};" > conftest.c
-    $CC $CFLAGS conftest.c -c -o conftest.o 2>/dev/null || die "endian test failed"
+    $CC conftest.c -c -o conftest.o 2>/dev/null || die "endian test failed"
     if (${cross_prefix}strings -a conftest.o | grep -q BIGE) && (${cross_prefix}strings -a conftest.o | grep -q FPendian) ; then
         define WORDS_BIGENDIAN
         CPU_ENDIAN="big-endian"
diff --git a/source/common/vec/intrinsic_intra-pred_avx2.c b/source/common/vec/intrinsic_intra-pred_avx2.c
index 0d078da..a34a206 100644
--- a/source/common/vec/intrinsic_intra-pred_avx2.c
+++ b/source/common/vec/intrinsic_intra-pred_avx2.c
@@ -298,7 +298,7 @@ void intra_pred_plane_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int b
         for (y = 0; y < bsy; y++) {
             D = _mm256_srai_epi16(T_Start, 5);
             D = _mm256_packus_epi16(D, D);
-            _mm256_maskstore_epi64((__int64*)dst, mask, D);
+            _mm256_maskstore_epi64((long long int *)dst, mask, D);
             T_Start = _mm256_add_epi16(T_Start, TC);
             dst += i_dst;
         }
@@ -308,7 +308,7 @@ void intra_pred_plane_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int b
             D = _mm256_srai_epi16(T_Start, 5);
             D = _mm256_packus_epi16(D, D);
             D = _mm256_permute4x64_epi64(D, 8);
-            _mm256_maskstore_epi64((__int64*)dst, mask, D);
+            _mm256_maskstore_epi64((long long int *)dst, mask, D);
             T_Start = _mm256_add_epi16(T_Start, TC);
             dst += i_dst;
         }
@@ -472,7 +472,7 @@ void intra_pred_bilinear_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
             T1 = _mm256_permute4x64_epi64(T1, 0x0008);
             T1 = _mm256_packus_epi16(T1, T1);
 
-            _mm256_maskstore_epi64((__int64*)dst, mask, T1);
+            _mm256_maskstore_epi64((long long int *)dst, mask, T1);
 
             dst += i_dst;
         }
@@ -525,7 +525,7 @@ void intra_pred_bilinear_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
                 T1 = _mm256_permutevar8x32_epi32(T1, mask1);
 
                 //store 128 bits
-                _mm256_maskstore_epi64((__int64*)(dst + x), mask2, T1);
+                _mm256_maskstore_epi64((long long int *)(dst + x), mask2, T1);
 
                 ADD = _mm256_add_epi32(ADD, T3);
             }
@@ -729,7 +729,7 @@ void intra_pred_ang_x_3_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
             __m256i mask = _mm256_loadu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
-            _mm256_maskstore_epi64((__int64*)&pfirst[0][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[0][i], mask, p00);
 
             p00 = _mm256_add_epi16(L5, L8);
             p10 = _mm256_add_epi16(L6, L7);
@@ -740,7 +740,7 @@ void intra_pred_ang_x_3_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)&pfirst[1][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[1][i], mask, p00);
 
             p00 = _mm256_mullo_epi16(L8, coeff3);
             p10 = _mm256_mullo_epi16(L9, coeff7);
@@ -753,7 +753,7 @@ void intra_pred_ang_x_3_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)&pfirst[2][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[2][i], mask, p00);
 
             p00 = _mm256_add_epi16(L11, L13);
             p10 = _mm256_mullo_epi16(L12, coeff2);
@@ -763,7 +763,7 @@ void intra_pred_ang_x_3_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)&pfirst[3][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[3][i], mask, p00);
         }
 
         bsy >>= 2;
@@ -818,16 +818,16 @@ void intra_pred_ang_x_3_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
             __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
             for (i = 0; i < bsy; i++) {
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i * 11));
-                _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst1, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i * 11));
-                _mm256_maskstore_epi64((__int64*)dst2, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst2, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[2] + i * 11));
-                _mm256_maskstore_epi64((__int64*)dst3, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst3, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[3] + i * 11));
-                _mm256_maskstore_epi64((__int64*)dst4, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst4, mask, M);
 
                 dst1 = dst4 + i_dst;
                 dst2 = dst1 + i_dst;
@@ -894,7 +894,7 @@ void intra_pred_ang_x_3_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
         p00 = _mm256_packus_epi16(p00, p00);
         p00 = _mm256_permute4x64_epi64(p00, 0x0008);
         __m256i mask = _mm256_loadu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
-        _mm256_maskstore_epi64((__int64*)dst1, mask, p00);
+        _mm256_maskstore_epi64((long long int *)dst1, mask, p00);
 
         p00 = _mm256_add_epi16(L5, L8);
         p10 = _mm256_add_epi16(L6, L7);
@@ -905,7 +905,7 @@ void intra_pred_ang_x_3_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
         p00 = _mm256_packus_epi16(p00, p00);
         p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-        _mm256_maskstore_epi64((__int64*)dst2, mask, p00);
+        _mm256_maskstore_epi64((long long int *)dst2, mask, p00);
 
         p00 = _mm256_mullo_epi16(L8, coeff3);
         p10 = _mm256_mullo_epi16(L9, coeff7);
@@ -918,7 +918,7 @@ void intra_pred_ang_x_3_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
         p00 = _mm256_packus_epi16(p00, p00);
         p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-        _mm256_maskstore_epi64((__int64*)dst3, mask, p00);
+        _mm256_maskstore_epi64((long long int *)dst3, mask, p00);
 
         p00 = _mm256_add_epi16(L11, L13);
         p10 = _mm256_mullo_epi16(L12, coeff2);
@@ -928,7 +928,7 @@ void intra_pred_ang_x_3_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
         p00 = _mm256_packus_epi16(p00, p00);
         p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-        _mm256_maskstore_epi64((__int64*)dst4, mask, p00);
+        _mm256_maskstore_epi64((long long int *)dst4, mask, p00);
 
     } else { //8x8 8x32 4x16 4x4
 
@@ -1020,7 +1020,7 @@ void intra_pred_ang_x_4_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
         sum1 = _mm256_permute4x64_epi64(sum1, 0x0008);
         //store 128 bit
         __m256i mask2 = _mm256_loadu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
-        _mm256_maskstore_epi64((__int64*)(first_line + i), mask2, sum1);
+        _mm256_maskstore_epi64((long long int *)(first_line + i), mask2, sum1);
 
         //_mm_storel_epi64((__m128i*)&first_line[i], sum1);
     }
@@ -1068,32 +1068,32 @@ void intra_pred_ang_x_4_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
         __m256i mask = _mm256_loadu_si256((const __m256i*)intrinsic_mask_256_8bit[bsx - 1]);
         for (i = 0; i < iHeight2; i += 8) {
             __m256i M = _mm256_loadu_si256((__m256i*)&first_line[i]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[i + 2]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[i + 4]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[i + 6]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
         }
     } else if (bsx == 8) {
         __m256i mask = _mm256_loadu_si256((const __m256i*)intrinsic_mask_256_8bit[bsx - 1]);
         for (i = 0; i < iHeight2; i += 8) {
             __m256i M = _mm256_loadu_si256((__m256i*)&first_line[i]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_srli_si256(M, 2);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_srli_si256(M, 2);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_srli_si256(M, 2);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
         }
     } else {
@@ -1440,7 +1440,7 @@ void intra_pred_ang_x_5_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
             __m256i mask = _mm256_loadu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
-            _mm256_maskstore_epi64((__int64*)&pfirst[0][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[0][i], mask, p00);
 
             p10 = _mm256_mullo_epi16(L3, coeff5);
             p20 = _mm256_mullo_epi16(L4, coeff7);
@@ -1453,7 +1453,7 @@ void intra_pred_ang_x_5_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)&pfirst[1][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[1][i], mask, p00);
 
             p00 = _mm256_mullo_epi16(L4, coeff7);
             p10 = _mm256_mullo_epi16(L5, coeff15);
@@ -1465,7 +1465,7 @@ void intra_pred_ang_x_5_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
             p00 = _mm256_srli_epi16(p00, 5);
 
             p00 = _mm256_packus_epi16(p00, p00);
-            _mm256_maskstore_epi64((__int64*)&pfirst[2][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[2][i], mask, p00);
 
             p00 = _mm256_add_epi16(L5, L8);
             p10 = _mm256_add_epi16(L6, L7);
@@ -1475,7 +1475,7 @@ void intra_pred_ang_x_5_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
             p00 = _mm256_srli_epi16(p00, 3);
 
             p00 = _mm256_packus_epi16(p00, p00);
-            _mm256_maskstore_epi64((__int64*)&pfirst[3][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[3][i], mask, p00);
 
             p00 = _mm256_add_epi16(L6, coeff16);
             p10 = _mm256_mullo_epi16(L7, coeff9);
@@ -1487,7 +1487,7 @@ void intra_pred_ang_x_5_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
             p00 = _mm256_srli_epi16(p00, 5);
 
             p00 = _mm256_packus_epi16(p00, p00);
-            _mm256_maskstore_epi64((__int64*)&pfirst[4][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[4][i], mask, p00);
 
             p00 = _mm256_mullo_epi16(L8, coeff3);
             p10 = _mm256_mullo_epi16(L9, coeff7);
@@ -1499,7 +1499,7 @@ void intra_pred_ang_x_5_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
             p00 = _mm256_srli_epi16(p00, 4);
 
             p00 = _mm256_packus_epi16(p00, p00);
-            _mm256_maskstore_epi64((__int64*)&pfirst[5][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[5][i], mask, p00);
 
             p00 = _mm256_mullo_epi16(L9, coeff3);
             p10 = _mm256_mullo_epi16(L10, coeff11);
@@ -1512,7 +1512,7 @@ void intra_pred_ang_x_5_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
             p00 = _mm256_srli_epi16(p00, 5);
 
             p00 = _mm256_packus_epi16(p00, p00);
-            _mm256_maskstore_epi64((__int64*)&pfirst[6][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[6][i], mask, p00);
 
             p00 = _mm256_add_epi16(L11, L13);
             p10 = _mm256_add_epi16(L12, L12);
@@ -1521,7 +1521,7 @@ void intra_pred_ang_x_5_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
             p00 = _mm256_srli_epi16(p00, 2);
 
             p00 = _mm256_packus_epi16(p00, p00);
-            _mm256_maskstore_epi64((__int64*)&pfirst[7][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[7][i], mask, p00);
         }
 
         bsy >>= 3;
@@ -1617,28 +1617,28 @@ void intra_pred_ang_x_5_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
             __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
             for (i = 0; i < bsy; i++) {
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i * 11));
-                _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst1, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i * 11));
-                _mm256_maskstore_epi64((__int64*)dst2, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst2, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[2] + i * 11));
-                _mm256_maskstore_epi64((__int64*)dst3, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst3, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[3] + i * 11));
-                _mm256_maskstore_epi64((__int64*)dst4, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst4, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[4] + i * 11));
-                _mm256_maskstore_epi64((__int64*)dst5, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst5, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[5] + i * 11));
-                _mm256_maskstore_epi64((__int64*)dst6, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst6, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[6] + i * 11));
-                _mm256_maskstore_epi64((__int64*)dst7, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst7, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[7] + i * 11));
-                _mm256_maskstore_epi64((__int64*)dst8, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst8, mask, M);
 
                 dst1 = dst8 + i_dst;
                 dst2 = dst1 + i_dst;
@@ -1715,7 +1715,7 @@ void intra_pred_ang_x_5_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
         p00 = _mm256_packus_epi16(p00, p00);
         p00 = _mm256_permute4x64_epi64(p00, 0x0008);
         __m256i mask = _mm256_loadu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
-        _mm256_maskstore_epi64((__int64*)dst1, mask, p00);
+        _mm256_maskstore_epi64((long long int *)dst1, mask, p00);
 
         p10 = _mm256_mullo_epi16(L3, coeff5);
         p20 = _mm256_mullo_epi16(L4, coeff7);
@@ -1728,7 +1728,7 @@ void intra_pred_ang_x_5_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
         p00 = _mm256_packus_epi16(p00, p00);
         p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-        _mm256_maskstore_epi64((__int64*)dst2, mask, p00);
+        _mm256_maskstore_epi64((long long int *)dst2, mask, p00);
 
         p00 = _mm256_mullo_epi16(L4, coeff7);
         p10 = _mm256_mullo_epi16(L5, coeff15);
@@ -1741,7 +1741,7 @@ void intra_pred_ang_x_5_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
         p00 = _mm256_packus_epi16(p00, p00);
         p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-        _mm256_maskstore_epi64((__int64*)dst3, mask, p00);
+        _mm256_maskstore_epi64((long long int *)dst3, mask, p00);
 
         p00 = _mm256_add_epi16(L5, L8);
         p10 = _mm256_add_epi16(L6, L7);
@@ -1752,7 +1752,7 @@ void intra_pred_ang_x_5_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
         p00 = _mm256_packus_epi16(p00, p00);
         p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-        _mm256_maskstore_epi64((__int64*)dst4, mask, p00);
+        _mm256_maskstore_epi64((long long int *)dst4, mask, p00);
 
 
     } else { //8x8 8x32 4x4 4x16
@@ -1840,7 +1840,7 @@ void intra_pred_ang_x_6_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
         sum1 = _mm256_permute4x64_epi64(sum1, 0x0008);
         //store 128 bit
         __m256i mask2 = _mm256_loadu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
-        _mm256_maskstore_epi64((__int64*)(first_line + i), mask2, sum1);
+        _mm256_maskstore_epi64((long long int *)(first_line + i), mask2, sum1);
 
         //_mm_storel_epi64((__m128i*)&first_line[i], sum1);
     }
@@ -1887,16 +1887,16 @@ void intra_pred_ang_x_6_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
         __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
         for (i = 0; i < bsy; i += 4) {
             __m256i M = _mm256_lddqu_si256((__m256i*)&first_line[i]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)&first_line[i + 1]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)&first_line[i + 2]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)&first_line[i + 3]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
         }
@@ -1904,16 +1904,16 @@ void intra_pred_ang_x_6_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
         __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[7]);
         for (i = 0; i < bsy; i += 4) {
             __m256i M = _mm256_lddqu_si256((__m256i*)&first_line[i]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)&first_line[i + 1]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)&first_line[i + 2]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)&first_line[i + 3]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
         }
@@ -2017,7 +2017,7 @@ void intra_pred_ang_x_7_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
                 D0 = _mm256_packus_epi16(D0, D0);
                 D0 = _mm256_permute4x64_epi64(D0, 0x00D8);
-                _mm256_maskstore_epi64((__int64*)dst, mask, D0);
+                _mm256_maskstore_epi64((long long int *)dst, mask, D0);
 
                 dst += i_dst;
             }
@@ -2203,7 +2203,7 @@ void intra_pred_ang_x_8_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
         p01 = _mm256_packus_epi16(p01, p01);
         p01 = _mm256_permute4x64_epi64(p01, 0x0008);
         __m256i mask = _mm256_loadu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
-        _mm256_maskstore_epi64((__int64*)&pfirst[0][i], mask, p01);
+        _mm256_maskstore_epi64((long long int *)&pfirst[0][i], mask, p01);
 
         p01 = _mm256_add_epi16(L1, L2);
         p02 = _mm256_add_epi16(L2, L3);
@@ -2214,7 +2214,7 @@ void intra_pred_ang_x_8_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
         p01 = _mm256_packus_epi16(p01, p01);
         p01=_mm256_permute4x64_epi64(p01,0x0008);
-        _mm256_maskstore_epi64((__int64*)&pfirst[1][i], mask, p01);
+        _mm256_maskstore_epi64((long long int *)&pfirst[1][i], mask, p01);
     }
 
     bsy >>= 1;
@@ -2309,62 +2309,62 @@ void intra_pred_ang_x_8_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
         __m256i mask = _mm256_loadu_si256((const __m256i*)intrinsic_mask_256_8bit[bsx - 1]);
         for (i = 0; i < bsy; i += 4) {
             __m256i M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i + 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i + 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i + 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i + 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i + 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i + 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
         }
     } else if (bsx == 8) {
         __m256i mask = _mm256_loadu_si256((const __m256i*)intrinsic_mask_256_8bit[bsx - 1]);
         for (i = 0; i < bsy; i += 4) {
             __m256i M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i + 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i + 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i + 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i + 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i + 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i + 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
         }
     } else {
@@ -2411,46 +2411,46 @@ void intra_pred_ang_x_8_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
         __m256i M1 = _mm256_loadu_si256((__m256i*)&pfirst[0][0]);
         __m256i M2 = _mm256_loadu_si256((__m256i*)&pfirst[1][0]);
-        _mm256_maskstore_epi64((__int64*)dst, mask, M1);
-        _mm256_maskstore_epi64((__int64*)(dst + i_dst), mask, M2);
+        _mm256_maskstore_epi64((long long int *)dst, mask, M1);
+        _mm256_maskstore_epi64((long long int *)(dst + i_dst), mask, M2);
         dst += i_dst2;
         M1 = _mm256_srli_si256(M1, 1);
         M2 = _mm256_srli_si256(M2, 1);
-        _mm256_maskstore_epi64((__int64*)dst, mask, M1);
-        _mm256_maskstore_epi64((__int64*)(dst + i_dst), mask, M2);
+        _mm256_maskstore_epi64((long long int *)dst, mask, M1);
+        _mm256_maskstore_epi64((long long int *)(dst + i_dst), mask, M2);
         dst += i_dst2;
         M1 = _mm256_srli_si256(M1, 1);
         M2 = _mm256_srli_si256(M2, 1);
-        _mm256_maskstore_epi64((__int64*)dst, mask, M1);
-        _mm256_maskstore_epi64((__int64*)(dst + i_dst), mask, M2);
+        _mm256_maskstore_epi64((long long int *)dst, mask, M1);
+        _mm256_maskstore_epi64((long long int *)(dst + i_dst), mask, M2);
         dst += i_dst2;
         M1 = _mm256_srli_si256(M1, 1);
         M2 = _mm256_srli_si256(M2, 1);
-        _mm256_maskstore_epi64((__int64*)dst, mask, M1);
-        _mm256_maskstore_epi64((__int64*)(dst + i_dst), mask, M2);
+        _mm256_maskstore_epi64((long long int *)dst, mask, M1);
+        _mm256_maskstore_epi64((long long int *)(dst + i_dst), mask, M2);
     } else { //8x32
         __m256i mask = _mm256_loadu_si256((const __m256i*)intrinsic_mask_256_8bit[bsx - 1]);
         for (i = 0; i < 16; i = i + 4) {
             __m256i M1 = _mm256_loadu_si256((__m256i*)&pfirst[0][i]);
             __m256i M2 = _mm256_loadu_si256((__m256i*)&pfirst[1][i]);
 
-            _mm256_maskstore_epi64((__int64*)dst, mask, M1);
-            _mm256_maskstore_epi64((__int64*)(dst + i_dst), mask, M2);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M1);
+            _mm256_maskstore_epi64((long long int *)(dst + i_dst), mask, M2);
             dst += i_dst2;
             M1 = _mm256_srli_si256(M1, 1);
             M2 = _mm256_srli_si256(M2, 1);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M1);
-            _mm256_maskstore_epi64((__int64*)(dst + i_dst), mask, M2);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M1);
+            _mm256_maskstore_epi64((long long int *)(dst + i_dst), mask, M2);
             dst += i_dst2;
             M1 = _mm256_srli_si256(M1, 1);
             M2 = _mm256_srli_si256(M2, 1);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M1);
-            _mm256_maskstore_epi64((__int64*)(dst + i_dst), mask, M2);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M1);
+            _mm256_maskstore_epi64((long long int *)(dst + i_dst), mask, M2);
             dst += i_dst2;
             M1 = _mm256_srli_si256(M1, 1);
             M2 = _mm256_srli_si256(M2, 1);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M1);
-            _mm256_maskstore_epi64((__int64*)(dst + i_dst), mask, M2);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M1);
+            _mm256_maskstore_epi64((long long int *)(dst + i_dst), mask, M2);
             dst += i_dst2;
             //M1 = _mm256_srli_si256(M1, 1);
             //M2 = _mm256_srli_si256(M2, 1);
@@ -2532,7 +2532,7 @@ void intra_pred_ang_x_9_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, int
 
                 D0 = _mm256_packus_epi16(D0, D0);
                 D0 = _mm256_permute4x64_epi64(D0, 0x00D8);
-                _mm256_maskstore_epi64((__int64*)dst, mask, D0);
+                _mm256_maskstore_epi64((long long int *)dst, mask, D0);
 
                 dst += i_dst;
             }
@@ -2774,7 +2774,7 @@ void intra_pred_ang_x_10_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
             __m256i mask = _mm256_loadu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
-            _mm256_maskstore_epi64((__int64*)&pfirst[0][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[0][i], mask, p00);
 
             p00 = _mm256_add_epi16(L1, L2);
             p00 = _mm256_mullo_epi16(p00, coeff3);
@@ -2785,7 +2785,7 @@ void intra_pred_ang_x_10_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)&pfirst[1][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[1][i], mask, p00);
 
             p10 = _mm256_mullo_epi16(L1, coeff5);
             p20 = _mm256_mullo_epi16(L2, coeff7);
@@ -2798,7 +2798,7 @@ void intra_pred_ang_x_10_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)&pfirst[2][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[2][i], mask, p00);
 
             p00 = _mm256_add_epi16(L1, L2);
             p10 = _mm256_add_epi16(L2, L3);
@@ -2808,7 +2808,7 @@ void intra_pred_ang_x_10_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)&pfirst[3][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[3][i], mask, p00);
         }
 
         bsy >>= 2;
@@ -2867,16 +2867,16 @@ void intra_pred_ang_x_10_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
             __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
             for (i = 0; i < bsy; i++) {
                 __m256i M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i));
-                _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst1, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i));
-                _mm256_maskstore_epi64((__int64*)dst2, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst2, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[2] + i));
-                _mm256_maskstore_epi64((__int64*)dst3, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst3, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[3] + i));
-                _mm256_maskstore_epi64((__int64*)dst4, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst4, mask, M);
 
                 dst1 += i_dstx4;
                 dst2 += i_dstx4;
@@ -2887,16 +2887,16 @@ void intra_pred_ang_x_10_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
             __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[7]);
             for (i = 0; i < bsy; i++) {
                 __m256i M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i));
-                _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst1, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i));
-                _mm256_maskstore_epi64((__int64*)dst2, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst2, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[2] + i));
-                _mm256_maskstore_epi64((__int64*)dst3, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst3, mask, M);
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[3] + i));
-                _mm256_maskstore_epi64((__int64*)dst4, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst4, mask, M);
 
                 dst1 += i_dstx4;
                 dst2 += i_dstx4;
@@ -3128,7 +3128,7 @@ void intra_pred_ang_x_11_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
 
             D0 = _mm256_packus_epi16(D0, D0);
             D0 = _mm256_permute4x64_epi64(D0, 0x00D8);
-            _mm256_maskstore_epi64((__int64*)dst, mask, D0);
+            _mm256_maskstore_epi64((long long int *)dst, mask, D0);
 
             dst += i_dst;
         }
@@ -3360,7 +3360,7 @@ void intra_pred_ang_y_25_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
         //
         //    p00 = _mm256_packus_epi16(p00, p01);
         //    p00 = _mm256_permute4x64_epi64(p00, 0x00D8);
-        //    _mm256_maskstore_epi64((__int64*)pfirst, mask, p00);
+        //    _mm256_maskstore_epi64((long long int *)pfirst, mask, p00);
         //
         //} else {
         //    __m256i mask = _mm256_set_epi64x(0, -1, -1, -1);
@@ -3411,7 +3411,7 @@ void intra_pred_ang_y_25_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
         //
         //    p00 = _mm256_packus_epi16(p00, p00);
         //    p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-        //    _mm256_maskstore_epi64((__int64*)pfirst, mask, p00);
+        //    _mm256_maskstore_epi64((long long int *)pfirst, mask, p00);
         //
         //}
 
@@ -3465,19 +3465,19 @@ void intra_pred_ang_y_25_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
             __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
             for (i = 0; i < iHeight8; i += 32) {
                 M = _mm256_lddqu_si256((__m256i*)(first_line + i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(first_line + i + 8));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(first_line + i + 16));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(first_line + i + 24));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
             }
         }
@@ -3742,19 +3742,19 @@ void intra_pred_ang_y_26_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
             for (i = 0; i < iHeight4; i += 16) {
 
                 M = _mm256_lddqu_si256((__m256i*)(first_line + i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(first_line + i + 4));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(first_line + i + 8));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(first_line + i + 12));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
             }
@@ -3762,19 +3762,19 @@ void intra_pred_ang_y_26_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
             __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[7]);
             for (i = 0; i < iHeight4; i += 16) {
                 M = _mm256_lddqu_si256((__m256i*)(first_line + i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(first_line + i + 4));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(first_line + i + 8));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(first_line + i + 12));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
             }
         }
@@ -3953,16 +3953,16 @@ void intra_pred_ang_y_28_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
         __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
         for (i = 0; i < iHeight2; i += 8) {
             __m256i M = _mm256_lddqu_si256((__m256i*)&first_line[i]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)&first_line[i + 2]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)&first_line[i + 4]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)&first_line[i + 6]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
         }
@@ -3970,16 +3970,16 @@ void intra_pred_ang_y_28_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
         __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[7]);
         for (i = 0; i < iHeight2; i += 8) {
             __m256i M = _mm256_lddqu_si256((__m256i*)&first_line[i]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)&first_line[i + 2]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)&first_line[i + 4]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)&first_line[i + 6]);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
         }
@@ -4118,7 +4118,7 @@ void intra_pred_ang_y_30_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
         p01 = _mm256_permute4x64_epi64(p01, 0x0008);
         p01 = _mm256_shuffle_epi8(p01, shuffle);
 
-        _mm256_maskstore_epi64((__int64*)&first_line[i], mask, p01);
+        _mm256_maskstore_epi64((long long int *)&first_line[i], mask, p01);
     }
 
     __m256i M;
@@ -4171,19 +4171,19 @@ void intra_pred_ang_y_30_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
         for (i = 0; i < bsy; i += 4) {
 
             M = _mm256_lddqu_si256((__m256i*)(first_line + i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(first_line + i + 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(first_line + i + 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(first_line + i + 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
         }
@@ -4191,19 +4191,19 @@ void intra_pred_ang_y_30_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
         mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[7]);
         for (i = 0; i < bsy; i += 4) {
             M = _mm256_lddqu_si256((__m256i*)(first_line + i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(first_line + i + 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(first_line + i + 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(first_line + i + 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
         }
     } else {
@@ -4241,65 +4241,65 @@ void intra_pred_ang_y_30_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
 
         if (bsy == 4) {
             __m256i M = _mm256_loadu_si256((__m256i*)&first_line[0]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[1]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[2]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[3]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
 
         } else {
             __m256i M = _mm256_loadu_si256((__m256i*)&first_line[0]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[1]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[2]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[3]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[4]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[5]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[6]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[7]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[8]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[9]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[10]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[11]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[12]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[13]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[14]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
             dst1 += i_dst;
             M = _mm256_loadu_si256((__m256i*)&first_line[15]);
-            _mm256_maskstore_epi64((__int64*)dst1, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst1, mask, M);
         }
     } else if (bsx == 8) {
 
@@ -4467,8 +4467,8 @@ void intra_pred_ang_y_32_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
         p10 = _mm256_permute4x64_epi64(p00, 0x0D);
         p00 = _mm256_permute4x64_epi64(p00, 0x08);
 
-        _mm256_maskstore_epi64((__int64*)&pfirst[0][i], mask, p00);
-        _mm256_maskstore_epi64((__int64*)&pfirst[1][i], mask, p10);
+        _mm256_maskstore_epi64((long long int *)&pfirst[0][i], mask, p00);
+        _mm256_maskstore_epi64((long long int *)&pfirst[1][i], mask, p10);
     }
 
     mask = _mm256_load_si256((__m256i*)intrinsic_mask_256_8bit[8]);
@@ -4495,8 +4495,8 @@ void intra_pred_ang_y_32_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
         p10 = _mm256_permute4x64_epi64(p00, 0x0D);
         p00 = _mm256_permute4x64_epi64(p00, 0x08);
 
-        _mm256_maskstore_epi64((__int64*)&pfirst[0][i], mask, p00);
-        _mm256_maskstore_epi64((__int64*)&pfirst[1][i], mask, p10);
+        _mm256_maskstore_epi64((long long int *)&pfirst[0][i], mask, p00);
+        _mm256_maskstore_epi64((long long int *)&pfirst[1][i], mask, p10);
         ;
     }
     bsy >>= 1;
@@ -4592,62 +4592,62 @@ void intra_pred_ang_y_32_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, in
         mask = _mm256_loadu_si256((const __m256i*)intrinsic_mask_256_8bit[bsx - 1]);
         for (i = 0; i < bsy; i += 4) {
             __m256i M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i + 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i + 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i + 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i + 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i + 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i + 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
         }
     } else if (bsx == 8) {
         mask = _mm256_loadu_si256((const __m256i*)intrinsic_mask_256_8bit[bsx - 1]);
         for (i = 0; i < bsy; i += 4) {
             __m256i M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i + 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i + 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i + 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i + 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] + i + 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] + i + 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
         }
     } else {
@@ -5217,70 +5217,70 @@ void intra_pred_ang_xy_13_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
             mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
             for (i = 0; i < bsy; i++) {
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[0] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[1] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[2] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[3] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[4] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[5] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[6] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[7] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
             }
         } else if (bsx == 8) {
             mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[7]);
             for (i = 0; i < bsy; i++) {
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[0] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[1] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[2] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[3] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[4] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[5] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[6] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[7] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
             }
         } else {
@@ -5417,10 +5417,10 @@ void intra_pred_ang_xy_14_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
             //0 4 8 12 16 20 24 28    1 5 9 13 17 21 25 29
             p10 = _mm256_permutevar8x32_epi32(p10, index);
 
-            ((__int64*)&pfirst[0][i])[0] = _mm256_extract_epi64(p10, 3);
-            ((__int64*)&pfirst[1][i])[0] = _mm256_extract_epi64(p10, 2);
-            ((__int64*)&pfirst[2][i])[0] = _mm256_extract_epi64(p10, 1);
-            ((__int64*)&pfirst[3][i])[0] = _mm256_extract_epi64(p10, 0);
+            ((long long int *)&pfirst[0][i])[0] = _mm256_extract_epi64(p10, 3);
+            ((long long int *)&pfirst[1][i])[0] = _mm256_extract_epi64(p10, 2);
+            ((long long int *)&pfirst[2][i])[0] = _mm256_extract_epi64(p10, 1);
+            ((long long int *)&pfirst[3][i])[0] = _mm256_extract_epi64(p10, 0);
 
         }
 
@@ -5577,7 +5577,7 @@ void intra_pred_ang_xy_14_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)&pfirst[2][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[2][i], mask, p00);
 
             p00 = _mm256_add_epi16(L1, L2);
             p00 = _mm256_mullo_epi16(p00, coeff3);
@@ -5588,7 +5588,7 @@ void intra_pred_ang_xy_14_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)&pfirst[1][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[1][i], mask, p00);
 
             p10 = _mm256_mullo_epi16(L1, coeff5);
             p20 = _mm256_mullo_epi16(L2, coeff7);
@@ -5601,7 +5601,7 @@ void intra_pred_ang_xy_14_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)&pfirst[0][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[0][i], mask, p00);
 
             p00 = _mm256_add_epi16(L0, L1);
             p10 = _mm256_add_epi16(L1, L2);
@@ -5611,7 +5611,7 @@ void intra_pred_ang_xy_14_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)&pfirst[3][i], mask, p00);
+            _mm256_maskstore_epi64((long long int *)&pfirst[3][i], mask, p00);
         }
 
         pfirst[0] += left_size;
@@ -5671,38 +5671,38 @@ void intra_pred_ang_xy_14_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
             __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
             for (i = 0; i < bsy; i++) {
                 __m256i M = _mm256_lddqu_si256((__m256i*)(pfirst[0] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[1] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[2] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[3] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
             }
         } else if (bsx == 8) {
             __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[7]);
             for (i = 0; i < bsy; i++) {
                 __m256i M = _mm256_lddqu_si256((__m256i*)(pfirst[0] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[1] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[2] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
 
                 M = _mm256_lddqu_si256((__m256i*)(pfirst[3] - i));
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
             }
         } else {
@@ -5767,7 +5767,7 @@ void intra_pred_ang_xy_14_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)dst3, mask, p00);
+            _mm256_maskstore_epi64((long long int *)dst3, mask, p00);
 
             p00 = _mm256_add_epi16(L1, L2);
             p00 = _mm256_mullo_epi16(p00, coeff3);
@@ -5778,7 +5778,7 @@ void intra_pred_ang_xy_14_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)dst2, mask, p00);
+            _mm256_maskstore_epi64((long long int *)dst2, mask, p00);
 
 
             p10 = _mm256_mullo_epi16(L1, coeff5);
@@ -5792,7 +5792,7 @@ void intra_pred_ang_xy_14_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)dst, mask, p00);
+            _mm256_maskstore_epi64((long long int *)dst, mask, p00);
 
             p00 = _mm256_add_epi16(L0, L1);
             p10 = _mm256_add_epi16(L1, L2);
@@ -5802,7 +5802,7 @@ void intra_pred_ang_xy_14_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
 
             p00 = _mm256_packus_epi16(p00, p00);
             p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-            _mm256_maskstore_epi64((__int64*)dst4, mask, p00);
+            _mm256_maskstore_epi64((long long int *)dst4, mask, p00);
         } else {//4x4
             pel_t *dst2 = dst + i_dst;
             pel_t *dst3 = dst2 + i_dst;
@@ -5940,8 +5940,8 @@ void intra_pred_ang_xy_16_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
         p10 = _mm256_permute4x64_epi64(p00, 0x08);//0 2
         p00 = _mm256_permute4x64_epi64(p00, 0x0D);//1 3
 
-        _mm256_maskstore_epi64((__int64*)&pfirst[0][i], mask1, p00);
-        _mm256_maskstore_epi64((__int64*)&pfirst[1][i], mask1, p10);
+        _mm256_maskstore_epi64((long long int *)&pfirst[0][i], mask1, p00);
+        _mm256_maskstore_epi64((long long int *)&pfirst[1][i], mask1, p10);
 
     }
 
@@ -5969,8 +5969,8 @@ void intra_pred_ang_xy_16_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
 
         p10 = _mm256_permute4x64_epi64(p01, 0x01);
 
-        _mm256_maskstore_epi64((__int64*)&pfirst[0][i], mask2, p10);
-        _mm256_maskstore_epi64((__int64*)&pfirst[1][i], mask2, p01);
+        _mm256_maskstore_epi64((long long int *)&pfirst[0][i], mask2, p10);
+        _mm256_maskstore_epi64((long long int *)&pfirst[1][i], mask2, p01);
     }
 
     src = pSrc1 + left_size + left_size;
@@ -6051,7 +6051,7 @@ void intra_pred_ang_xy_16_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
 
         p00 = _mm256_packus_epi16(p00, p00);
         p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-        _mm256_maskstore_epi64((__int64*)&pfirst[0][i], mask1, p00);
+        _mm256_maskstore_epi64((long long int *)&pfirst[0][i], mask1, p00);
 
         p00 = _mm256_add_epi16(L0, L1);
         p01 = _mm256_add_epi16(L1, L2);
@@ -6061,7 +6061,7 @@ void intra_pred_ang_xy_16_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
 
         p00 = _mm256_packus_epi16(p00, p00);
         p00 = _mm256_permute4x64_epi64(p00, 0x0008);
-        _mm256_maskstore_epi64((__int64*)&pfirst[1][i], mask1, p00);
+        _mm256_maskstore_epi64((long long int *)&pfirst[1][i], mask1, p00);
 
     }
 
@@ -6161,62 +6161,62 @@ void intra_pred_ang_xy_16_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
         __m256i mask = _mm256_loadu_si256((const __m256i*)intrinsic_mask_256_8bit[bsx - 1]);
         for (i = 0; i < bsy; i += 4) {
             __m256i M = _mm256_lddqu_si256((__m256i*)(pfirst[0] - i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] - i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] - i - 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] - i - 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] - i - 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] - i - 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] - i - 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] - i - 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
         }
     } else if (bsx == 8) {
         __m256i mask = _mm256_loadu_si256((const __m256i*)intrinsic_mask_256_8bit[bsx - 1]);
         for (i = 0; i < bsy; i += 4) {
             __m256i M = _mm256_lddqu_si256((__m256i*)(pfirst[0] - i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] - i));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] - i - 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] - i - 1));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] - i - 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] - i - 2));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
 
             M = _mm256_lddqu_si256((__m256i*)(pfirst[0] - i - 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             M = _mm256_lddqu_si256((__m256i*)(pfirst[1] - i - 3));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
         }
     } else {
@@ -6346,7 +6346,7 @@ void intra_pred_ang_xy_18_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
         sum1 = _mm256_packus_epi16(sum1, sum1);
         sum1 = _mm256_permute4x64_epi64(sum1, 0x00D8);
 
-        _mm256_maskstore_epi64((__int64*)&first_line[i], mask, sum1);
+        _mm256_maskstore_epi64((long long int *)&first_line[i], mask, sum1);
     }
 
     __m256i M;
@@ -6406,22 +6406,22 @@ void intra_pred_ang_xy_18_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
         __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
         for (i = 0; i < bsy; i += 4) {
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst--;
 
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst--;
 
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst--;
 
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst--;
         }
@@ -6429,22 +6429,22 @@ void intra_pred_ang_xy_18_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
         __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[7]);
         for (i = 0; i < bsy; i += 4) {
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst--;
 
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst--;
 
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst--;
 
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst--;
         }
@@ -6662,7 +6662,7 @@ void intra_pred_ang_xy_20_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
 
         sum1 = _mm256_packus_epi16(sum1, sum1);
         sum1 = _mm256_permute4x64_epi64(sum1, 0x00D8);
-        _mm256_maskstore_epi64((__int64*)&first_line[i], mask, sum1);
+        _mm256_maskstore_epi64((long long int *)&first_line[i], mask, sum1);
     }
 
     if (bsx == 64) {
@@ -6757,19 +6757,19 @@ void intra_pred_ang_xy_20_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
         mask = _mm256_loadu_si256((const __m256i*)intrinsic_mask_256_8bit[bsx - 1]);
         for (i = 0; i < bsy; i += 4) {
             __m256i M = _mm256_lddqu_si256((__m256i*)(pfirst));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst -= 2;
             M = _mm256_lddqu_si256((__m256i*)(pfirst));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst -= 2;
             M = _mm256_lddqu_si256((__m256i*)(pfirst));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst -= 2;
             M = _mm256_lddqu_si256((__m256i*)(pfirst));
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst -= 2;
 
@@ -6779,35 +6779,35 @@ void intra_pred_ang_xy_20_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
         mask = _mm256_loadu_si256((const __m256i*)intrinsic_mask_256_8bit[bsx - 1]);
         for (i = 0; i < bsy; i += 8) {
             __m256i M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst -= 2;
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst -= 2;
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst -= 2;
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst -= 2;
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst -= 2;
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst -= 2;
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst -= 2;
             M = _mm256_lddqu_si256((__m256i*)pfirst);
-            _mm256_maskstore_epi64((__int64*)dst, mask, M);
+            _mm256_maskstore_epi64((long long int *)dst, mask, M);
             dst += i_dst;
             pfirst -= 2;
         }
@@ -7097,7 +7097,7 @@ void intra_pred_ang_xy_22_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
             sum1 = _mm256_packus_epi16(sum1, sum1);
             sum1 = _mm256_permute4x64_epi64(sum1, 0x00D8);
 
-            _mm256_maskstore_epi64((__int64*)&first_line[i], mask, sum1);
+            _mm256_maskstore_epi64((long long int *)&first_line[i], mask, sum1);
 
 
         }
@@ -7159,22 +7159,22 @@ void intra_pred_ang_xy_22_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
             __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
             for (i = 0; i < bsy; i += 4) {
                 M = _mm256_lddqu_si256((__m256i*)pfirst);
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
                 pfirst -= 4;
 
                 M = _mm256_lddqu_si256((__m256i*)pfirst);
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
                 pfirst -= 4;
 
                 M = _mm256_lddqu_si256((__m256i*)pfirst);
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
                 pfirst -= 4;
 
                 M = _mm256_lddqu_si256((__m256i*)pfirst);
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
                 pfirst -= 4;
             }
@@ -7182,22 +7182,22 @@ void intra_pred_ang_xy_22_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
             __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[7]);
             for (i = 0; i < bsy; i += 4) {
                 M = _mm256_lddqu_si256((__m256i*)pfirst);
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
                 pfirst -= 4;
 
                 M = _mm256_lddqu_si256((__m256i*)pfirst);
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
                 pfirst -= 4;
 
                 M = _mm256_lddqu_si256((__m256i*)pfirst);
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
                 pfirst -= 4;
 
                 M = _mm256_lddqu_si256((__m256i*)pfirst);
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
                 pfirst -= 4;
             }
@@ -7505,22 +7505,22 @@ void intra_pred_ang_xy_23_avx(pel_t *src, pel_t *dst, int i_dst, int dir_mode, i
             __m256i mask = _mm256_lddqu_si256((__m256i*)intrinsic_mask_256_8bit[15]);
             for (i = 0; i < bsy; i += 4) {
                 M = _mm256_lddqu_si256((__m256i*)pfirst);
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
                 pfirst -= 8;
 
                 M = _mm256_lddqu_si256((__m256i*)pfirst);
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
                 pfirst -= 8;
 
                 M = _mm256_lddqu_si256((__m256i*)pfirst);
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
                 pfirst -= 8;
 
                 M = _mm256_lddqu_si256((__m256i*)pfirst);
-                _mm256_maskstore_epi64((__int64*)dst, mask, M);
+                _mm256_maskstore_epi64((long long int *)dst, mask, M);
                 dst += i_dst;
                 pfirst -= 8;
             }
diff --git a/source/encoder/encoder.c b/source/encoder/encoder.c
index d5b3890..42ac9be 100644
--- a/source/encoder/encoder.c
+++ b/source/encoder/encoder.c
@@ -2038,7 +2038,7 @@ void *xavs2e_encode_one_frame(void *arg)
 
     /* start AEC frame coding */
     if (h->h_top->threadpool_aec != NULL && !h->param->enable_alf) {
-        xavs2_threadpool_run(h->h_top->threadpool_aec, encoder_aec_encode_one_frame, h, 0);
+        // xavs2_threadpool_run(h->h_top->threadpool_aec, (xavs2_tfunc_t)encoder_aec_encode_one_frame, h, 0);
     }
 
     /* (3) encode all LCU rows in current frame ---------------------------
@@ -2147,7 +2147,7 @@ void *xavs2e_encode_one_frame(void *arg)
 #endif
 
         if (h->h_top->threadpool_aec != NULL) {
-            xavs2_threadpool_run(h->h_top->threadpool_aec, encoder_aec_encode_one_frame, h, 0);
+            xavs2_threadpool_run(h->h_top->threadpool_aec, (xavs2_tfunc_t)encoder_aec_encode_one_frame, h, 0);
         }
     }
 
diff --git a/source/encoder/parameters.c b/source/encoder/parameters.c
index 9adec5b..d14e564 100644
--- a/source/encoder/parameters.c
+++ b/source/encoder/parameters.c
@@ -528,7 +528,7 @@ char *copy_parameter(char *dst, const char *src)
  *          : less than 2M bytes
  * ---------------------------------------------------------------------------
  */
-static char *xavs2_get_configs(int argc, const char * const *argv)
+static char *xavs2_get_configs(int argc, char *argv[])
 {
     const int size_file_max = 1 << 20; // 1MB
     char item[4096];
